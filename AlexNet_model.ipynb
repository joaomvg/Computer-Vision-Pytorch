{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "import progressbar\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, img_shape=(1,3,32,32),num_classes=1000,dropout_rate=0):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        #CONV. Layers\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Dropout2d(0.4),\n",
    "            nn.Conv2d(3, 96, kernel_size=6, stride=1, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            #original paper uses 2GPU's, so the architecture is split in two main channels which are fed to each GPU\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        input_shape= img_shape\n",
    "        self.out_conv_dim=self.get_conv_dim(input_shape)\n",
    "        \n",
    "        #FFN Layers\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.out_conv_dim, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_conv_dim(self,shape):\n",
    "        x = torch.rand(shape)\n",
    "        x = self.conv_stack(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        \n",
    "        return x.size(1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_stack(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(obj):\n",
    "    classname = obj.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.kaiming_normal_(obj.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(obj.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(obj.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AlexNet(dropout_rate=0.4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34042664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d : CNN\n",
      "Conv2d : CNN\n",
      "Conv2d : CNN\n",
      "Conv2d : CNN\n",
      "Conv2d : CNN\n"
     ]
    }
   ],
   "source": [
    "for module in model.modules():\n",
    "    name=module.__class__.__name__\n",
    "    if name.find('Conv')!=-1:\n",
    "        print(name,\": CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/notebooks/datasets/fastai/cifar10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_dir+'train'\n",
    "data_test=data_dir+'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir+'labels.txt') as file:\n",
    "    labels=file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_folders=os.listdir(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_images={}\n",
    "for folder in category_folders:\n",
    "    category_images[folder]=os.listdir(data_train+'/'+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(data_train+'/bird/'+category_images['bird'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr=np.array(img)\n",
    "img_arr=img_arr.transpose(2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch=torch.tensor(img_arr.astype(np.float32))\n",
    "img_torch=img_torch.view(1,img_torch.size(0),img_torch.size(1),img_torch.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img_torch.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.out_conv_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bird',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'truck']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir+'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Dataset(Dataset):\n",
    "    def __init__(self, data_dir, data_size = 0, transforms = None):\n",
    "        label_folders = os.listdir(data_dir)\n",
    "        folders_path = [os.path.join(data_dir,x) for x in label_folders]\n",
    "        \n",
    "        files=[(os.path.join(path,x),label) for label,path in zip(label_folders,folders_path) for x in os.listdir(path)]\n",
    "        \n",
    "        if data_size < 0 or data_size > len(files):\n",
    "            assert(\"Data size should be between 0 to number of files in the dataset\")\n",
    "        \n",
    "        if data_size == 0:\n",
    "                \n",
    "            data_size=len(files)\n",
    "        \n",
    "        self.data_size = data_size\n",
    "        self.files = random.sample(files, self.data_size)\n",
    "        self.transforms = transforms\n",
    "        self.label_mapping={label:i for i,label in enumerate(label_folders)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_address = self.files[idx]\n",
    "        image = Image.open(image_address[0])\n",
    "        image=np.array(image).astype(np.float32)\n",
    "        label_name = image_address[1]\n",
    "        label = self.label_mapping[label_name]\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image.transpose(2,1,0), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/datasets/fastai/cifar10/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=Cifar10Dataset(data_dir+'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/notebooks/datasets/fastai/cifar10/train/bird/18727_bird.png', 'bird')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bird': 0,\n",
       " 'dog': 1,\n",
       " 'cat': 2,\n",
       " 'ship': 3,\n",
       " 'horse': 4,\n",
       " 'automobile': 5,\n",
       " 'airplane': 6,\n",
       " 'frog': 7,\n",
       " 'deer': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=Cifar10Dataset(data_dir+'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl=torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, criterion, optimizer, device):\n",
    "    L=len(train_loader)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train() # Make sure that the model is in training mode.\n",
    "\n",
    "        total_loss = 0\n",
    "        if epoch==1:\n",
    "            iterator=tqdm(train_loader)\n",
    "        else:\n",
    "            iterator=train_loader\n",
    "            \n",
    "        for batch in iterator:\n",
    "            # get data\n",
    "            batch_x, batch_y = batch\n",
    "            \n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # get predictions from model\n",
    "            y_pred = model(batch_x)\n",
    "        \n",
    "            # perform backprop\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "        if epoch%5==0:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(train_data.label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AlexNet(num_classes=num_classes,dropout_rate=0.4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv_stack): Sequential(\n",
       "    (0): Dropout2d(p=0.4, inplace=False)\n",
       "    (1): Conv2d(3, 96, kernel_size=(6, 6), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_stack): Sequential(\n",
       "    (0): Dropout(p=0.4, inplace=False)\n",
       "    (1): Linear(in_features=2304, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters(),lr=0.001,weight_decay=0.0001,momentum=0.0001)\n",
    "loss_fn=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:20<00:00, 18.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.30565856656302576\n",
      "Epoch: 10, Loss: 0.29849484149376143\n",
      "Epoch: 15, Loss: 0.29564154102369344\n",
      "Epoch: 20, Loss: 0.2818283721461625\n"
     ]
    }
   ],
   "source": [
    "train(model,train_dl,20,loss_fn,optimizer,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,val_dl):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "        accu=0\n",
    "        for batch in val_dl:\n",
    "            val_X,val_y=batch\n",
    "            val_X=val_X.to(device)\n",
    "            val_y=val_y.to(device)\n",
    "            x=model(val_X)\n",
    "            probs=F.softmax(x,dim=1)\n",
    "            preds=probs.argmax(dim=1)\n",
    "            accu+=(preds==val_y).sum().item()\n",
    "    \n",
    "  accu=accu/len(val_dl.dataset)*100\n",
    "  return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.872"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model,train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.96000000000001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
